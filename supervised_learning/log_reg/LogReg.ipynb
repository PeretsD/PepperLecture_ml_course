{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9231e410",
   "metadata": {},
   "source": [
    "# Logistic Regression (Логистическая регрессия)\n",
    "\n",
    "Применение алгоритма Логистическая регрессия для решения задачи классификации.\n",
    "\n",
    "\n",
    "### Датасет\n",
    "Рассматривать задачу будем на примере известного датасета **Цветки Ириса**\n",
    "\n",
    "Датасет [Цветки Ириса](https://archive.ics.uci.edu/ml/datasets/iris) содержит 150 записей, каждая из записей содержит 4 признака, т.е. $\\boldsymbol x \\in \\mathbb{R}^4$. \n",
    "\n",
    "Что за 4 признака?\n",
    "\n",
    "0. длина чашелистника, см\n",
    "1. ширина чашелистника, см\n",
    "2. длина лепестка, см \n",
    "3. ширина лепестка, см \n",
    "\n",
    "Метки классов\n",
    "\n",
    "0. Setosa\n",
    "1. Versicolour \n",
    "2. Virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8da282f",
   "metadata": {},
   "source": [
    "## 0. Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32de47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# программная реализация алгоритма логистическая регрессия\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# программная реализация расчета метрики точности\n",
    "from sklearn.metrics import accuracy_score\n",
    "# модуль для разделения выборки на тестовую и обучающую\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# модуль, позволяющий подтягивать данные по хрестоматийным примерам для ML\n",
    "from sklearn import datasets\n",
    "\n",
    "# модули визуализации данных\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# библиотеки для работы с матрицами\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5281cac0",
   "metadata": {},
   "source": [
    "## 1. Загружаем данные по цветкам ирисов\n",
    "\n",
    "Для этого воспользуемся встроенным в библиотеке `scikit-learn` модулем `datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c855174",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f17cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750591ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Информация по признакам\n",
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48420ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Информация по целевой переменной (классам цветка)\n",
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba89825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведем информацию по размерности датасета и целевой переменной\n",
    "# чтобы убедиться, что размерности совпадают\n",
    "print('Размерность признакового пространства {}'.format(iris.data.shape))\n",
    "print('Размерность вектора целевой переменной {}'.format(iris.target.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae9c42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вынесем признаки и целевую перемнную в отдельные переменные\n",
    "X = iris.data[:, :4] \n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446d2a8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Посмотрим на гистограмму распределения целевой переменной\n",
    "sns.histplot(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eceb410",
   "metadata": {},
   "source": [
    "Данные очень хорошо сбалансированы - каждого класса по 50 объектов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cefcc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Посмотрим на распределения признаков\n",
    "for i in range(4):\n",
    "    # создадим пустой график (для каждого признака создаем свое полотно)\n",
    "    plt.figure\n",
    "    # построим гистограмму для выбранного признака\n",
    "    sns.histplot(X[:,i]);\n",
    "    # добавим подпись к оси x\n",
    "    plt.xlabel(iris.feature_names[i])\n",
    "    # отобразим график\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c4a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим dataframe на основании исходных данных\n",
    "# для простоты отображения графиков\n",
    "iris_df = pd.DataFrame(np.c_[iris.data, iris.target], columns=['sepal length (cm)', \n",
    "                                                               'sepal width (cm)', \n",
    "                                                               'petal length (cm)',\n",
    "                                                               'petal width (cm)',\n",
    "                                                               'class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c785385e",
   "metadata": {},
   "source": [
    "## Матрица Корреляций\n",
    "\n",
    "Корреляционная матрица показывает взаимосвязи между переменными набора данных.\n",
    "\n",
    "Корреляционная матрица представляет собой матричную структуру, которая помогает программистую анализировать взаимосвязь между переменными данных. Он представляет собой корреляционное значение между диапазоном 0 и 1.\n",
    "\n",
    "Положительное значение представляет хорошую корреляцию, и отрицательное значение представляет собой низкую корреляцию и значение, эквивалентное нулю (0), не представляет зависимости между конкретным набором переменных.\n",
    "\n",
    "Какие выводы можно сделать на основании этой матрицы?\n",
    "- Найти линейно зависимые признаки;\n",
    "- Помогает выбрать важные и незначимые переменные набора данных на основании линейной зависимости/независимости с целевой переменной.\n",
    "\n",
    ">Матрица корреляций применима только к числовым/непрерывным переменным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8731580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для получения матрицы корреляций можно воспользоваться функцией corr для объекта DataFrame\n",
    "corr_matrix = iris_df.corr()\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fbf645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для наглядного отображения воспользуемся библиотекой seaborn\n",
    "sns.heatmap(corr_matrix, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a666e5d1",
   "metadata": {},
   "source": [
    "# 2. Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79f6b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиение на тестовую и обучающую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f8c137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим объект класса LogosticRegression\n",
    "classifier_LR = LogisticRegression(random_state=21, max_iter=1000, multi_class='multinomial')\n",
    "\n",
    "# Обучение модели\n",
    "classifier_LR.fit(X_train, y_train)\n",
    "\n",
    "# Прогноз\n",
    "y_pred = classifier_LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47332457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведем точность модели\n",
    "print('Точность: {:.2f}'.format(classifier_LR.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53742264",
   "metadata": {},
   "source": [
    "Как мы говороли на лекции, логистическая регрессия - линейный алгоритм классификации, который ищет веса коэффициентов для признаков. Т.к. мы решаем задачу мультклассификации, то в используемой реализации `sklearn` веса представляют собой не просто вектор размерности (1,4), а (3,4), т.е. для каждого класса отдельно считается его принадлежность. Для просмотра коэффициентов, необходимо воспользоваться функцией `coef_` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d220ad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_LR.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707a9468",
   "metadata": {},
   "source": [
    "> # Задание\n",
    ">\n",
    "> При помощи GridSearchCV выбрать наиболее оптимальный набор параметров для C из множества (0.001, 0.01, 0.1, 1, 10) и для penalty из множества ('l1','l2'). Ниже дана справка по тому, что за параметры l1 и l2, C и какой функцией можно реализовать перебор параметров. Необходимо определить, какой метод регуляризации наиболее применим для выбранных данных и насколько необходимо \"подстраиваться\" под линейно неразделимые точки. В качестве ответа нужно указать какой тип регуляризации наиболее оптимален. Во втором поле ответа необходимо указать какое количество весовых коэффициентов было обнулено.\n",
    "\n",
    "### Параметр штрафа `C`\n",
    "Параметр `C` компенсирует неправильную классификацию обучающих примеров простотой поверхности принятия решений.\n",
    "\n",
    "\n",
    "### l1 и l2 регуляризация\n",
    "Регуляризация - метод добавления некоторых дополнительных ограничений к условию с целью решить некорректно поставленную задачу или предотвратить переобучение. Эта информация часто имеет вид штрафа за сложность модели. Например, это могут быть ограничения гладкости результирующей функции или ограничения по норме векторного пространства.\n",
    "\n",
    "Основные виды регуляризации:\n",
    "\n",
    "$L_{1}$-регуляризация (англ. lasso regression), или регуляризация через манхэттенское расстояние:\n",
    "\n",
    "$$L_{1}=\\sum _{i}{(y_{i}-y(t_{i}))}^{2}+\\lambda \\sum _{i}{|a_{i}|}$$\n",
    "\n",
    "$L_{2}$- регуляризация, или регуляризация Тихонова (в англоязычной литературе — ridge regression или Tikhonov regularization), для интегральных уравнений позволяет балансировать между соответствием данным и маленькой нормой решения:\n",
    "\n",
    "$$L_{2}=\\sum _{i}{(y_{i}-y(t_{i}))}^{2}+\\lambda \\sum _{i}{a_{i}}^{2}$$\n",
    "\n",
    "$L_1$-регуляризация реализует это путём отбора наиболее важных факторов, которые сильнее всего влияют на результат. Для простоты можете считать, что факторы с малой величиной влияния на конечный результат фактически «помогают» вам предсказывать лишь шум в наборе обучающих данных. $L_2$ -регуляризация предотвращает переобучения модели путём запрета на непропорционально большие весовые коэффициенты.\n",
    "\n",
    "При $L_2$-регуляризации дополнительный член является квадратичной функцией, при $L_1$-регуляризации – модулем.\n",
    "\n",
    "Как мы уже говорили, машинное обучение это про решение задачи оптимизации, а это как следствие, обычно приводит нас к поиску производной. При квадратичном члене, чем ближе к нулю, тем меньшей становится производная, пока также не приблизится к нулю. Поэтому при $L_2$-регуляризации, когда оптимизируемая величина уже мала, дальнейший градиентный спуск её сильно не изменит. В случае модуля производная является константой с абсолютной величиной, равной единице. Формально в нуле она не определена, но мы считаем её также равной нулю. Поэтому при $L_1$-регуляризации градиентный спуск будет стремиться к нулю с постоянной скоростью, а достигнув его, там и останется. Вследствие этого $L_2$-регуляризация способствует малой величине весовых коэффициентов, а $L_1$-регуляризация способствует их равенству нулю, тем самым провоцируя разрежённость.\n",
    "\n",
    "### GridSearchCV\n",
    "\n",
    "У каждого из алгоритмов есть определенный набор параметров, которые необходимо подобрать в процессе обучения модели. Но как оптимальнее всего автоматизировать этот процесс? Первое, что приходит в голову, это использовать циклы, внутри которых будем перебирать различные параметры модели. Но каждый раз описывать эти циклы довольно рутинно и неинтересно. Именно поэтому в библиотеке `Scikit-Learn` рализован инструмент перебора параметров, который называется `GridSearchCV`.\n",
    "`GridSearchCV` – это очень мощный инструмент для автоматического подбора параметров для моделей машинного обучения. `GridSearchCV` находит наилучшие параметры, путем обычного перебора: он создает модель для каждой возможной комбинации параметров. Также есть `RandomSearchCV` - это когда мы перебираем не по полной сетке возможных комбинаций параметров, а случайным образом выбираем комбинации и обучаем модели на них. Магические буквы `CV` - это кросс-валидация, пока параметр, отвечающий за этот функционал мы просто оставим равным 3, далее в лекциях поговорим что это такое и как с этим работать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6093173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт нужного модуля для поиска параметров\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# создадим словарь для перебора параметров\n",
    "parameters = {\n",
    "    'C':,\n",
    "    'penalty':\n",
    "}\n",
    "\n",
    "# создадим объект модели \n",
    "classifier_logreg = LogisticRegression(\n",
    "    random_state=21, \n",
    "    max_iter=10000, \n",
    "    multi_class='multinomial', \n",
    "    solver='saga'\n",
    ")\n",
    "\n",
    "# создадим объект GridSearchCV\n",
    "clf=GridSearchCV(classifier_logreg, param_grid=parameters, cv=3)\n",
    "\n",
    "# обучение модели по сетке гиперпараметров\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fc181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для вывода параметров наилучшей модели можно воспользоваться\n",
    "# best_params_\n",
    "print(clf.)\n",
    "\n",
    "# Для вывода лучшей метрики best_score_\n",
    "print(\"Точность :\",clf.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517079ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для обращения к лучшей модели best_estimator_\n",
    "# При помощи coef_ можно получить матрицу коэффициентов модели"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
